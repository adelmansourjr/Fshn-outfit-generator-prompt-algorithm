# FSHN: Wardrobe Indexing + Outfit Recommender ("Pseudo Tensor-Network" Scoring)

This repo is a two-step pipeline:

1. **Index your wardrobe images** with `classify_images.ts` → produces `index.json` (structured metadata per item).
2. **Recommend outfits/items from a prompt** with `recommend_from_prompt_tn.ts` → uses Gemini (Vertex AI) to parse intent, then scores items/outfits using a *factor-graph / pseudo tensor-network* objective plus diversity sampling.

The core idea: treat an outfit as a set of discrete choices (top/bottom/shoes/mono) and score it with **unary** terms (item ↔ prompt) and **pairwise** terms (item ↔ item compatibility). The code calls this “tensor-network style” because it’s equivalent to a small tensor/factor contraction in log-space, but implemented directly as sums of factors.

---

## Repo layout

- `classify_images.ts` — builds `index.json` from a folder of images using Google Cloud Vision.
- `recommend_from_prompt_tn.ts` — prompt → intent(JSON) via Gemini → scoring → sampled recommendations.
- `images/` — put wardrobe images here (or point to another folder).
- `index.json` — example output (generated by the classifier).
- `micro-edge-478816-f5-5225f93c6887.json` — (looks like) a GCP credential file; avoid committing keys.

---

## Requirements

- Node.js 18+ recommended
- A Google Cloud project with:
	- **Cloud Vision API** enabled (for `classify_images.ts`)
	- **Vertex AI API** enabled (for `recommend_from_prompt_tn.ts`)

### Authentication (ADC)

Both scripts use Google client libraries that rely on **Application Default Credentials**.

Option A (recommended for local dev):

```zsh
gcloud auth application-default login
```

Option B (service account key):

```zsh
export GOOGLE_APPLICATION_CREDENTIALS="/absolute/path/to/service-account.json"
```

Security note: don’t commit key JSONs. If a key was committed, revoke/rotate it.

---

## Install

From the repo root:

```zsh
npm ci
```

---

## Step 1: Build the wardrobe index (`index.json`)

`classify_images.ts` reads images from a directory and writes a JSON array of items.

### Supported image formats

The classifier only includes files matching `*.jpg`, `*.jpeg`, `*.png`.

### Run

```zsh
npx ts-node classify_images.ts \
	--images_dir images \
	--out index.json
```

Optional flags:

- `--min_colours` (default `1`, clamped to `1..2`): guarantee at least that many colours
- `--names_json`: optional mapping to improve product naming

Example with both:

```zsh
npx ts-node classify_images.ts \
	--images_dir images \
	--out index.json \
	--min_colours 2 \
	--names_json names.json
```

### `names.json` format

`--names_json` should be a JSON object mapping either the **full filename** or the **basename** to a nicer product name:

```json
{
	"IMG_1234.jpg": "Black hoodie",
	"yeezy_gap_dove": "Yeezy Gap Dove Hoodie"
}
```

### What the classifier extracts

For each image it calls Cloud Vision:

- `labelDetection`
- `imageProperties` (dominant colours)
- `webDetection` (web entities + best-guess)
- `logoDetection`
- `textDetection` (OCR)

It then builds tokens from those sources plus the filename/product name, and derives:

- `category`: one of `top | bottom | shoes | mono`
- `colours`: canonical palette: `black white grey red blue green beige brown pink yellow purple`
- `vibes`: `streetwear edgy minimal y2k techwear sporty preppy vintage chic`
- `gender`: `men | women | unisex`
- `fit` (tops/bottoms): `oversized | regular | slim | cropped` (or `null`)
- `sportMeta` (only when it actually looks sporty):
	- `sport`: `football | basketball | running | tennis | gym | other`
	- `teams`: list of normalized team aliases
	- `isKit`: boolean for “looks like an official kit”
- `entities` / `entityMeta`: deduped bag of entity strings (from logos/web/OCR/name) with weights and a coarse type: `brand | team | sponsor | generic`

### `index.json` schema (what the recommender consumes)

Each element looks like:

```json
{
	"id": "somefile.jpg",
	"imagePath": "images/somefile.jpg",
	"category": "top",
	"sub": "hoodie",
	"colours": ["black","grey"],
	"vibes": ["streetwear"],
	"gender": "unisex",
	"fit": "oversized",
	"sportMeta": null,
	"name": "Yeezy Gap Dove Hoodie",
	"name_normalized": "yeezy gap dove hoodie",
	"entities": ["yeezy","gap","dove"],
	"entityMeta": [{"text":"yeezy","weight":0.9,"type":"brand"}]
}
```

Note: `imagePath` is whatever `path.join(images_dir, filename)` produced. If `images_dir` is relative, `imagePath` will be relative.

---

## Step 2: Recommend from a prompt (Gemini + TN-style scoring)

`recommend_from_prompt_tn.ts` loads `index.json`, parses your prompt into an “intent” JSON via Gemini (Vertex), then scores and samples recommendations.

### Run

```zsh
npx ts-node recommend_from_prompt_tn.ts \
	--index index.json \
	--prompt "playboi carti fit with timberlands" \
	--project "YOUR_GCP_PROJECT_ID"
```

Common options (all are real CLI flags in the script):

- `--location` (default `us-east5`)
- `--model` (default `gemini-2.5-flash`)
- `--gender_pref` one of `any | men | women` (default `any`)
- `--pool_size` number of results to print (default `6`)
- `--per_role_limit` cap candidates per role before combinatorics (default `12`)
- `--epsilon` diversity mixing factor (default `0.15`, clamped to `0..1`)
- `--jitter` uniform noise added to scores (default `0.15`)
- `--debug` or env var `DEBUG_OUTFITS=1` to print debug info to stderr

Example:

```zsh
DEBUG_OUTFITS=1 \
npx ts-node recommend_from_prompt_tn.ts \
	--index index.json \
	--prompt "all black techwear fit, oversized top with slim bottoms" \
	--project "YOUR_GCP_PROJECT_ID" \
	--pool_size 6 \
	--per_role_limit 14 \
	--epsilon 0.2 \
	--jitter 0.15
```

### Output format

The output is plain text:

- One line per selected item as: `category imagePath`
- Categories print in this fixed order: `top`, `bottom`, `shoes`, `mono`
- Each outfit is separated by a blank line

---

# Algorithm (read this if you care about the math)

## 1) Prompt → intent JSON (Gemini) + heuristic repair

The script always computes a **heuristic intent** from the prompt (string matching) and then asks Gemini (Vertex AI) to produce a strict JSON object with this shape:

```ts
interface PromptIntent {
	outfit_mode: "outfit" | "single";
	requested_form:
		| "top_bottom_shoes" | "top_bottom"
		| "mono_only" | "mono_and_shoes"
		| "top_only" | "bottom_only" | "shoes_only";
	required_categories: ("top"|"bottom"|"shoes"|"mono")[];
	optional_categories: ("top"|"bottom"|"shoes"|"mono")[];
	target_gender: "men" | "women" | "unisex" | "any";
	vibe_tags: ("streetwear"|"edgy"|"minimal"|"y2k"|"techwear"|"sporty"|"preppy"|"vintage"|"chic")[];
	colour_hints: ("black"|"white"|"grey"|"red"|"blue"|"green"|"beige"|"brown"|"pink"|"yellow"|"purple")[];
	brand_focus: string[];
	team_focus: string[];
	sport_context: "football"|"basketball"|"running"|"tennis"|"gym"|"other"|"none";
	fit_preference: "oversized"|"regular"|"slim"|"cropped"|"mixed"|null;
	specific_items: string[];
}
```

Then it **repairs** Gemini’s output:

- If Gemini returns no categories → copy from heuristic intent.
- If Gemini says `outfit` but only 1 category while heuristics found a fuller outfit → “upgrade” to heuristic categories.

This keeps the recommender usable even if the model under-specifies.

## 2) Intent → weight vectors (the “context tensor”)

The intent is converted into numeric weight tables:

- `wColour[colour]`
	- if `colour_hints` is empty: adds a neutral baseline (`black/white/grey/beige`)
	- otherwise, hinted colours get weight `+1.0`
- `wVibe[vibe]`: each vibe in `vibe_tags` gets `+1.0`
- `wFit[fit]`:
	- if explicit fit (not `mixed`): set all fits to `0.1` and chosen fit to `1.0`
	- else: bias toward `regular` with some mass on `oversized` and `slim`
- `wSport[sport]`:
	- one-hot if `sport_context !== none`
	- else all zeros
- `brandTokens`, `teamTokens`: normalized strings from `brand_focus` / `team_focus`
- `specificTokens`: words extracted from `specific_items` (e.g. “timberland”, “boots”)

These tables are the “context tensor” in the loose sense: a compact representation of what the prompt wants.

## 3) Single-item scoring (unary factors)

Each item gets a single score:

$$
S_\text{single}(i) =
w_c\,\phi_c(i) +
w_v\,\phi_v(i) +
w_f\,\phi_f(i) +
w_b\,\phi_b(i) +
w_s\,\phi_s(i) +
w_t\,\phi_t(i) +
w_{sp}\,\phi_{sp}(i)
$$

Where the implementation uses these multipliers:

- `WEIGHT_SINGLE.color = 1.0`
- `WEIGHT_SINGLE.vibe = 1.2`
- `WEIGHT_SINGLE.fit = 0.8`
- `WEIGHT_SINGLE.brand = 1.0`
- `WEIGHT_SINGLE.sport = 1.0`
- `WEIGHT_SINGLE.team = 1.2`
- `WEIGHT_SINGLE.specific = 1.5`

And the feature terms are:

### Colour alignment `φc`

- Take the max `wColour` among the item’s colours.
- If the user expressed colour preferences (total weight > 0) and the item matches none → subtract `0.5`.
- If the item contains a neutral (`black/white/grey/beige/brown`) → add `0.2 * maxNeutralWeight`.

### Vibe alignment `φv`

- Sum `wVibe[v]` over item vibes.
- If the user expressed vibes and the item matches none → subtract `0.3`.

### Fit alignment `φf`

- Use `item.fit` (defaulting to `regular`) and look up `wFit[fit]`.

### Brand alignment `φb`

- For each token in `brandTokens`:
	- if it appears in `name`/`name_normalized` → +1.0
	- if it appears in `entityMeta.text` bag → +1.5

### Sport alignment `φs`

- Base: `wSport[item.sportMeta.sport]`.
- If the prompt is sporty and the item is a kit (`isKit`) → +0.5.
- If the prompt is not sporty (`sport_context == none`) but the item is sporty:
	- kit → -0.7
	- non-kit sport item → -0.4

### Team alignment `φt`

- Looks in `sportMeta.teams`, team-typed `entityMeta`, and a combined text bag.
- Adds ~1.0–1.5 per matching team token.

### Specific-item alignment `φsp`

- For each word token in `specificTokens`, if it appears anywhere in name/path/entities → +1.0.

This single score is the “unary potential” for the factor graph.

## 4) Candidate filtering (search control)

Before outfit assembly, the code builds per-role candidate pools:

1. Filter by `category`.
2. If `sport_context !== none` and there exist sport-relevant items for that role → keep only sport-relevant.
3. Run staged constraints (stop at the first stage that yields a non-empty pool):
	 - require brand + team + strong sport
	 - require team + strong sport
	 - require strong sport
	 - no strong constraints
4. If `specificTokens` exist, it keeps items in that pool with the **maximum count** of matching specific tokens.

Finally, it scores the pool by `S_single` and truncates to `--per_role_limit`.

## 5) Outfit scoring (pairwise factors)

An outfit is a set of chosen items (depending on form):

$$
x = (x_\text{top}, x_\text{bottom}, x_\text{shoes}, x_\text{mono})
$$

The total score is:

$$
S(x) = \sum_r S_\text{single}(x_r) + \sum_{(r,s)} S_\text{pair}(x_r, x_s)
$$

Pairwise multipliers in code:

- `WEIGHT_PAIR.color = 0.6`
- `WEIGHT_PAIR.vibe = 0.9`
- `WEIGHT_PAIR.fit = 0.7`
- `WEIGHT_PAIR.sport = 0.8`
- `WEIGHT_PAIR.team = 1.0`

Pairwise feature terms:

### Colour compatibility

- Average over all colour pairs:
	- exact match → +1.0
	- both neutrals → +0.6
	- one neutral → +0.4

### Vibe compatibility

- `sharedVibes + crossBonus`
- Cross-bonuses:
	- `streetwear` + `sporty` → +0.5
	- `chic` + `minimal` → +0.4

### Fit compatibility (top↔bottom only)

- Rewards silhouettes like oversized top + slim bottom (1.3) and penalizes oversized+oversized (0.4).

### Sport compatibility

- If prompt is non-sport:
	- both non-sport → 0
	- one sport mixed in → -0.2
	- two sport pieces → -0.5
- If prompt is sport:
	- same sport → +1.0
	- different sport → +0.2
	- if either is non-sport → 0

### Team compatibility

- Same team → +1.2
- Mixed teams (when both have team metadata) → -0.3

This is the “pseudo tensor-network”: you can interpret each unary/pairwise term as a small tensor (factor), and the outfit score as a contraction in log-space, but the implementation just sums factors explicitly.

## 6) Diversity sampling (epsilon + jitter)

After scoring:

1. Add score noise: `score += Uniform(-jitter, +jitter)`.
2. Sort descending.
3. Keep a “top band” of size `max(pool_size*3, pool_size)`.
4. Repeatedly pick until `pool_size` results:
	 - with probability `epsilon`: weighted-random pick from the band
	 - else: take the current best
5. De-dupe exact outfits by item-id signature.

`--epsilon` increases variety; `--jitter` makes rankings less deterministic.

---

## Quick tuning cheatsheet

- Want more variety? Increase `--epsilon` (e.g. `0.25`) and/or `--jitter` (e.g. `0.2`).
- Want higher quality / less randomness? Reduce `--epsilon` and `--jitter`.
- Want deeper search? Increase `--per_role_limit` (but watch combinatorics).

---

## Troubleshooting

- **Auth errors**: confirm ADC is set (`gcloud auth application-default login`) or `GOOGLE_APPLICATION_CREDENTIALS` points to a valid key.
- **No outfits produced**: your `index.json` may have too few items per category; try adding more images or lowering constraints in the prompt.
- **Only sport items show up / sport items leak**: the code heavily prioritizes sport relevance when `sport_context` is detected; remove sport words from the prompt if you want non-sport fits.

